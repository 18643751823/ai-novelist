# AI 小说家 MVP 项目计划书

## 1. 项目目标 (MVP)

*   验证 Electron 桌面应用壳与 Node.js 后端、**基于 HTTP 接口的 `mcp-filesystem-server`** 之间通信的可行性。
*   实现最基本的文件创建、读取和写入操作，以验证 **AI 大模型** 对文件系统的控制能力。
*   构建一个极简的用户界面，展示核心交互流程。

## 2. MVP 核心功能

### 2.1. 前端用户界面 (UI)

*   **技术**：Electron + 纯 HTML/CSS/JavaScript (或最简化的前端框架，如 Vue/React 的 CDN 版本，用于快速原型)。
*   **布局**：
    *   **小说正文编辑框**：一个简单的 `<textarea>` 元素，用于显示和编辑纯文本内容。允许用户手动输入和 AI 输出。
    *   **用户与 AI 交互聊天框**：包含一个文本输入框（用户输入自然语言指令）和一个显示区域（显示用户指令、AI 的思考过程、工具调用指令和 AI 的回复）。
*   **文件操作显示**：在聊天框或编辑框上方显示当前操作的文件名。

### 2.2. 后端 AI 逻辑 (Node.js)

*   **技术**：Node.js
*   **意图识别与工具规划**：
    *   **由 AI 大模型负责意图识别和工具规划。** Node.js 后端将用户的自然语言指令发送给大模型（如 DeepSeek）。
    *   大模型根据用户意图和预定义的工具描述，判断是否需要调用 `mcp-filesystem-server` 提供的工具（如 `read_file`, `write_file`）。
    *   **大模型将自己的思考和调用工具的指令以固定格式（例如 JSON）返回给 Node.js 后端。**
*   **MCP 文件系统交互模块**：
    *   功能：Node.js 后端接收并解析大模型返回的工具调用指令。
    *   `mcp-filesystem-server` 已成功修改为支持 HTTP 接口。Node.js 后端（`main.js`）已成功修改为通过 **HTTP 请求** 调用 `mcp-filesystem-server` 提供的 HTTP API 来执行文件系统操作（如 `read_file`, `write_file`）。
    实现Node.js 后端接收并解析大模型返回的工具调用指令。
    *   **未来扩展方向（通用 MCP 客户端框架）**：考虑到未来可能需要与更多类型的 MCP 服务器通信，本项目将探讨并可能实现一个通用的 MCP 客户端框架。该框架将模仿 `Roo Code` 与 MCP 服务器的通信方式（尤其针对本地 Stdio-based 服务器），使 `AI小说家` 能够动态地接入和使用多种 MCP 工具。此方案将作为当前 HTTP 方案的升级或备选。
    *   参数传递：将大模型指令中解析出的文件名和内容传递给 MCP 工具。

### 2.3. 前后端通信与部署

*   **通信**：
    *   **Electron IPC (Inter-Process Communication)**：前端 (渲染进程) 通过 `ipcRenderer.invoke()` 发送用户自然语言指令给主进程。主进程通过 `ipcMain.handle()` 接收指令，处理后通过 `ipcMain.handle()` 返回结果（包括 AI 回复、文件操作结果等）给渲染进程。
    *   **Node.js 后端与 MCP 通信**：Node.js 后端（运行在 Electron 主进程中）将直接通过 **HTTP 请求** 与 `mcp-filesystem-server` 进行通信。
*   **部署**：
    *   **本地运行**：通过 `electron .` 命令在开发模式下运行。
    *   **打包**：MVP 阶段可以跳过完整的打包过程，主要关注本地运行和测试。

### 2.4. 数据结构与文件存储

*   **章节内容**：
    *   存储为简单的纯文本 (`.txt`) 文件，位于 `D:\ai小说家` 目录下。
    *   文件命名：用户直接指定文件名，例如 `test.txt`。
*   **无元数据管理**：MVP 阶段不涉及小说元数据管理。

## 3. MVP 验证闭环

基于大模型驱动的工具使用流程，以下是优化后的闭环环节：

1.  **用户在 UI 聊天框输入自然语言指令。** (例如: `帮我新建一个名为“我的第一章”的文件`)
2.  **Electron 前端通过 IPC 将用户的自然语言指令发送给 Node.js 后端。**
3.  **Node.js 后端（`main.js`）将用户指令连同预定义的 MCP 工具描述发送给 AI 大模型（DeepSeek）。**
4.  **AI 大模型根据用户指令和工具描述，判断是否需要调用工具，并返回信息。信息应该包含：1对用户要求的分析与回复，2如果有调用工具的需求，则先分析使用工具的先后顺序，然后在分析的末尾输出工具调用指令（例如 `{"tool_name": "write_file", "parameters": {"path": "我的第一章.txt"}}`）或纯文本回复。**
5.  **Node.js 后端接收 AI 大模型的响应。**
    *   如果响应包含工具调用指令，Node.js 后端解析该指令，提取工具名称和参数。
    *   如果响应是纯文本回复，或者工具调用指令不正确，Node.js 后端将该回复通过 IPC 返回给前端 UI 显示，如果工具调用指令不正确，node,js还会把错误信息发给大模型。
6.  **Node.js 后端将 AI 大模型返回的信息，工具调用指令显示在前端 UI 的聊天框中，供用户观察与确认执行。**
7.  **用户确认执行后，Node.js 后端根据解析出的工具名称和参数，构建并向 `mcp-filesystem-server` 发送 HTTP 请求。** (例如：向 `http://localhost:端口号/write_file` 发送 POST 请求，包含 `path: "我的第一章.txt"`)如果用户取消执行，则node.js将取消执行的信息存储好，等到合适的时机发送给大模型。
8.  **`mcp-filesystem-server` 接收 HTTP 请求，执行相应的操作（例如，创建 `D:\ai小说家\我的第一章.txt` 空文件）。**
9.  **`mcp-filesystem-server` 将操作结果（例如：成功/失败消息）通过 HTTP 响应返回给 Node.js 后端。**
10. **Node.js 后端接收 `mcp-filesystem-server` 的 HTTP 响应，处理操作结果。**
11. **Node.js 后端将操作结果通过 IPC 发送回前端。**
12. **前端在聊天框中显示“文件创建成功”或失败消息。**

## 4. 后续任务

*   **实现 AI 驱动的工具使用 (Function Calling)**：这是当前最优先的任务。
    *   **更新 `main.js` 中的 AI 调用逻辑**：
        *   将工具的执行结果以 `tool` 角色再次作为上下文发送回 DeepSeek，让 AI 获得工具执行的反馈，从而生成接下来的回复或者工具调用操作。
*   **前端**：引入 Markdown 编辑器、章节目录展示、更复杂的 UI 布局。
*   **后端**：实现更多 `mcp-filesystem-server` 工具的调用（如 `delete_file`, `list_directory`）。
*   **数据**：引入小说元数据管理。
*   **通用 MCP 客户端框架**：分析 `Roo Code` 与 MCP 服务器（尤其是本地 Stdio-based 服务器）的通用通信协议和机制，实现 `AI小说家` 内部的通用 MCP 客户端框架，以便未来能够动态地接入和使用多种 MCP 服务器。此方案将作为当前 HTTP 方案的升级或备选。

